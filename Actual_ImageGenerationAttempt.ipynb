{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"66JgbYL0_2q8"},"outputs":[],"source":["# IMPORTS\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.applications.resnet import ResNet50\n","from keras.applications.resnet import preprocess_input, decode_predictions\n","from keras.models import Sequential\n","from keras.layers import Dense, Reshape, Conv2D, Flatten, UpSampling2D, LeakyReLU\n","from matplotlib import pyplot as plt\n","import random\n","\n","# from keras.preprocessing import image\n","import keras.utils as image\n","from google.colab import drive\n","import numpy as np\n","import os\n","\n","\n","from keras.utils import array_to_img\n","from keras.callbacks import Callback\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21714,"status":"ok","timestamp":1683820699732,"user":{"displayName":"Jalen Mccloud","userId":"17934253152405445319"},"user_tz":240},"id":"vUwDTNVyAt9l","outputId":"eb39d138-0f33-4073-ce5b-7f04859f61e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/College/Senior 2nd Semester/CPSC 4300\n"]}],"source":["# THIS STUFF IS FOR GOOGLE COLAB ONLY\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/College/Senior\\ 2nd\\ Semester/CPSC\\ 4300/\n","\n","\n","# print(os.listdir('./resized_Images/train/'))\n","# print(os.listdir('./ADS_Project'))\n","# print(os.listdir('./ADS_Project/Vincent_van_Gogh'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoHxcfr59Xzz"},"outputs":[],"source":["# DONT NEED TO RUN THIS\n","\n","\n","\"\"\"  This section's code labels all the images in a folder  \"\"\"\n","\n","# THIS IS THE CODE THAT WORKS\n","# MOST OF CODE IS FROM KERAS APPLICATION DOCUMENTATION\n","# It IS USING RESNET50, A PRETRAINED MODEL, TO LABEL IMAGES\n","# TAKES ABOUT 3 MIN TO RUN\n","# NEED TO LIMIT RANGE TO 400-500 IMAGES NOT FULL FOLDER\n","model = ResNet50(weights='imagenet')\n","\n","label_list = []\n","\n","# Loops through every file (picture) in folder\n","# Only loops through 450 files\n","directory = os.fsencode('./ADS_Project/Vincent_van_Gogh')\n","for file in os.listdir(directory)[1:451]:\n","  filename = os.fsdecode(file)\n","  print(filename)\n","\n","  img_path = './ADS_Project/Vincent_van_Gogh/' + filename\n","  img = image.load_img(img_path, target_size=(224, 224))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","  x = preprocess_input(x)\n","\n","  preds = model.predict(x)\n","  # decode the results into a list of tuples (class, description, probability)\n","  # (one such list for each sample in the batch)\n","  print('Predicted:', decode_predictions(preds, top=3)[0])\n","  # Returns the top=K labels of the image\n","\n","  label_list.append(decode_predictions(preds, top=3)[0])\n","\n","  # Example\n","  # Vincent_van_Gogh_107.jpg\n","  # 1/1 [==============================] - 1s 896ms/step\n","  # Predicted: [('n03450230', 'gown', 0.19037418), ('n03874599', 'padlock', 0.14866965), ('n03617480', 'kimono', 0.13832778), ('n04259630', 'sombrero', 0.05663917), ('n02999410', 'chain', 0.045607608)]\n","\n","\"\"\"  End of image labeling section  \"\"\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1682522846494,"user":{"displayName":"Jalen Mccloud","userId":"17934253152405445319"},"user_tz":240},"id":"Fq2W_c5e7z8g","outputId":"2474f625-22f2-4119-9856-1bf42652edb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['n04366367', 'n04259630', 'n02749479', 'n07248320', 'n03598930', 'n02793495', 'n04522168', 'n03388043', 'n11879895', 'n03938244', 'n07753275', 'n03763968', 'n03891251', 'n02883205', 'n03724870', 'n03598930', 'n03598930', 'n03991062', 'n02837789', 'n03291819', 'n03992509', 'n04606251', 'n04081281', 'n09256479', 'n02980441', 'n03617480', 'n03457902', 'n07248320', 'n09332890', 'n12768682', 'n04606251', 'n04326547', 'n04476259', 'n04371774', 'n03991062', 'n09472597', 'n03000134', 'n12768682', 'n04599235', 'n03598930', 'n02643566', 'n03724870', 'n09468604', 'n06596364', 'n07753275', 'n03598930', 'n09256479', 'n04326547', 'n03000134', 'n03388043', 'n03891251', 'n03598930', 'n02536864', 'n09332890', 'n04389033', 'n07248320', 'n01768244', 'n04476259', 'n03930313', 'n01688243', 'n03598930', 'n04596742', 'n09256479', 'n03598930', 'n02793495', 'n03891251', 'n07248320', 'n03950228', 'n06596364', 'n07248320', 'n07248320', 'n04326547', 'n07248320', 'n03991062', 'n04589890', 'n04522168', 'n07248320', 'n09472597', 'n03388043', 'n04485082', 'n07248320', 'n03388043', 'n03000134', 'n02980441', 'n03930313', 'n03598930', 'n09472597', 'n02422699', 'n07248320', 'n03992509', 'n03617480', 'n02793495', 'n06596364', 'n03028079', 'n03045698', 'n07715103', 'n03991062', 'n12620546', 'n03223299', 'n03028079', 'n01695060', 'n03598930', 'n03903868', 'n03991062', 'n04326547', 'n02481823', 'n04259630', 'n09246464', 'n03388043', 'n03763968', 'n02727426', 'n01828970', 'n03530642', 'n03598930', 'n01986214', 'n07802026', 'n02980441', 'n03598930', 'n03598930', 'n07248320', 'n03028079', 'n04355338', 'n03992509', 'n02980441', 'n03388043', 'n03930313', 'n03598930', 'n09332890', 'n03372029', 'n03598930', 'n04523525', 'n03388043', 'n03485794', 'n03388043', 'n01704323', 'n03124043', 'n03598930', 'n03887697', 'n01630670', 'n03598930', 'n09193705', 'n07802026', 'n02980441', 'n09256479', 'n03598930', 'n06596364', 'n04326547', 'n04326547', 'n06596364', 'n07248320', 'n03598930', 'n02233338', 'n03598930', 'n02233338', 'n02793495', 'n02916936', 'n03598930', 'n06596364', 'n03724870', 'n12985857', 'n09472597', 'n03598930', 'n04532670', 'n02101556', 'n04326547', 'n03903868', 'n02823428', 'n04326547', 'n02791270', 'n03724870', 'n02823428', 'n03743016', 'n09472597', 'n04326547', 'n02793495', 'n02692877', 'n06596364', 'n09246464', 'n01698640', 'n09246464', 'n06596364', 'n03014705', 'n02134084', 'n04465501', 'n09193705', 'n03649909', 'n02692877', 'n02793495', 'n02865351', 'n03929855', 'n10565667', 'n04005630', 'n01687978', 'n04347754', 'n04325704', 'n09246464', 'n09246464', 'n03598930', 'n03697007', 'n02966193', 'n07768694', 'n09246464', 'n04326547', 'n03000684', 'n11879895', 'n03598930', 'n02980441', 'n02788148', 'n04099969', 'n02793495', 'n13133613', 'n06596364', 'n02808304', 'n03930313', 'n07248320', 'n04326547', 'n03388043', 'n02793495', 'n07248320', 'n02793495', 'n03598930', 'n03598930', 'n02395406', 'n03028079', 'n03598930', 'n09332890', 'n03763968', 'n03047690', 'n04532106', 'n07248320', 'n03930313', 'n03598930', 'n07248320', 'n11879895', 'n07248320', 'n03388043', 'n03598930', 'n03598930', 'n03028079', 'n02980441', 'n03598930', 'n09256479', 'n02793495', 'n03028079', 'n03787032', 'n07248320', 'n02980441', 'n09256479', 'n02980441', 'n12985857', 'n03598930', 'n03763968', 'n04209133', 'n03384352', 'n06596364', 'n02319095', 'n04606251', 'n04099969', 'n07248320', 'n04429376', 'n09246464', 'n02096051', 'n03240683', 'n02219486', 'n02951358', 'n03598930', 'n09256479', 'n02793495', 'n03598930', 'n03598930', 'n09246464', 'n03530642', 'n03028079', 'n09256479', 'n03598930', 'n01755581', 'n02116738', 'n09332890', 'n04604644', 'n07248320', 'n02134084', 'n03998194', 'n03967562', 'n01768244', 'n09193705', 'n03598930', 'n03930313', 'n03598930', 'n03598930', 'n02793495', 'n02699494', 'n03598930', 'n04326547', 'n07248320', 'n09193705', 'n04209133', 'n07248320', 'n02138441', 'n03998194', 'n09246464', 'n03598930', 'n02980441', 'n04326547', 'n04325704', 'n07248320', 'n11879895', 'n03991062', 'n03598930', 'n03598930', 'n01688243', 'n03967562', 'n06596364', 'n03598930', 'n02793495', 'n04005630', 'n02980441', 'n04326547', 'n01768244', 'n03598930', 'n03598930', 'n03598930', 'n03388043', 'n02219486', 'n11879895', 'n03124170', 'n03598930', 'n02130308', 'n03891332', 'n07248320', 'n07802026', 'n04606251', 'n07248320', 'n07248320', 'n03028079', 'n10565667', 'n03388043', 'n04606251', 'n09256479', 'n04259630', 'n12985857', 'n07248320', 'n02692877', 'n07248320', 'n03388043', 'n03388043', 'n03028079', 'n03388043', 'n02793495', 'n03781244', 'n04326547', 'n07248320', 'n04606251', 'n04589890', 'n07248320', 'n04326547', 'n04371774', 'n07248320', 'n03598930', 'n03950228', 'n04606251', 'n07248320', 'n04209239', 'n03938244', 'n03743016', 'n04204347', 'n01978455', 'n03291819', 'n07248320', 'n02391049', 'n06596364', 'n07248320', 'n03598930', 'n03598930', 'n07248320', 'n09468604', 'n04326547', 'n03724870', 'n09193705', 'n03876231', 'n03763968', 'n04458633', 'n13052670', 'n04326547', 'n04604644', 'n03649909', 'n04090263', 'n03992509', 'n06596364', 'n02398521', 'n04209239', 'n07248320', 'n03967562', 'n04417672', 'n09246464', 'n02793495', 'n03598930', 'n01990800', 'n02793495', 'n07248320', 'n07248320', 'n03388043', 'n04131690', 'n03216828', 'n07248320', 'n04326547', 'n02486410', 'n02793495', 'n03743016', 'n02699494', 'n03028079', 'n03991062', 'n02865351', 'n03763968', 'n04417672', 'n03874599', 'n03534580', 'n03291819', 'n03291819', 'n07248320', 'n11879895', 'n02793495', 'n02948072', 'n02692877', 'n04606251', 'n03291819', 'n04326547', 'n04482393', 'n03457902', 'n03598930', 'n04326547', 'n03598930', 'n03991062', 'n03598930', 'n03950228', 'n07248320', 'n03598930', 'n03388043', 'n03998194', 'n09246464', 'n02980441', 'n07802026', 'n07714571', 'n03598930', 'n04417672', 'n03874599', 'n04326547', 'n03028079', 'n02841315', 'n02980441', 'n03141823']\n","['suspension_bridge', 'sombrero', 'assault_rifle', 'book_jacket', 'jigsaw_puzzle', 'barn', 'vase', 'fountain', 'rapeseed', 'pillow', 'pineapple', 'military_uniform', 'park_bench', 'bow_tie', 'mask', 'jigsaw_puzzle', 'jigsaw_puzzle', 'pot', 'bikini', 'envelope', \"potter's_wheel\", 'wreck', 'restaurant', 'coral_reef', 'castle', 'kimono', 'greenhouse', 'book_jacket', 'lakeside', 'buckeye', 'wreck', 'stone_wall', 'tray', 'swing', 'pot', 'volcano', 'chainlink_fence', 'buckeye', 'wool', 'jigsaw_puzzle', 'lionfish', 'mask', 'valley', 'comic_book', 'pineapple', 'jigsaw_puzzle', 'coral_reef', 'stone_wall', 'chainlink_fence', 'fountain', 'park_bench', 'jigsaw_puzzle', 'coho', 'lakeside', 'tank', 'book_jacket', 'trilobite', 'tray', 'picket_fence', 'frilled_lizard', 'jigsaw_puzzle', 'wok', 'coral_reef', 'jigsaw_puzzle', 'barn', 'park_bench', 'book_jacket', 'pitcher', 'comic_book', 'book_jacket', 'book_jacket', 'stone_wall', 'book_jacket', 'pot', 'window_screen', 'vase', 'book_jacket', 'volcano', 'fountain', 'tripod', 'book_jacket', 'fountain', 'chainlink_fence', 'castle', 'picket_fence', 'jigsaw_puzzle', 'volcano', 'impala', 'book_jacket', \"potter's_wheel\", 'kimono', 'barn', 'comic_book', 'church', 'cloak', 'cauliflower', 'pot', 'hip', 'doormat', 'church', 'Komodo_dragon', 'jigsaw_puzzle', 'pedestal', 'pot', 'stone_wall', 'chimpanzee', 'sombrero', 'cliff', 'fountain', 'military_uniform', 'apiary', 'bee_eater', 'honeycomb', 'jigsaw_puzzle', 'hermit_crab', 'hay', 'castle', 'jigsaw_puzzle', 'jigsaw_puzzle', 'book_jacket', 'church', 'sundial', \"potter's_wheel\", 'castle', 'fountain', 'picket_fence', 'jigsaw_puzzle', 'lakeside', 'flute', 'jigsaw_puzzle', 'vault', 'fountain', 'handkerchief', 'fountain', 'triceratops', 'cowboy_boot', 'jigsaw_puzzle', 'paper_towel', 'common_newt', 'jigsaw_puzzle', 'alp', 'hay', 'castle', 'coral_reef', 'jigsaw_puzzle', 'comic_book', 'stone_wall', 'stone_wall', 'comic_book', 'book_jacket', 'jigsaw_puzzle', 'cockroach', 'jigsaw_puzzle', 'cockroach', 'barn', 'bulletproof_vest', 'jigsaw_puzzle', 'comic_book', 'mask', 'coral_fungus', 'volcano', 'jigsaw_puzzle', 'viaduct', 'clumber', 'stone_wall', 'pedestal', 'beer_bottle', 'stone_wall', 'barbershop', 'mask', 'beer_bottle', 'megalith', 'volcano', 'stone_wall', 'barn', 'airship', 'comic_book', 'cliff', 'American_alligator', 'cliff', 'comic_book', 'chest', 'ice_bear', 'tractor', 'alp', 'lawn_mower', 'airship', 'barn', 'bolo_tie', 'pickelhaube', 'scuba_diver', 'prison', 'agama', 'submarine', 'stole', 'cliff', 'cliff', 'jigsaw_puzzle', 'lumbermill', 'carousel', 'pomegranate', 'cliff', 'stone_wall', 'chain_saw', 'rapeseed', 'jigsaw_puzzle', 'castle', 'bannister', 'rocking_chair', 'barn', 'ear', 'comic_book', 'bath_towel', 'picket_fence', 'book_jacket', 'stone_wall', 'fountain', 'barn', 'book_jacket', 'barn', 'jigsaw_puzzle', 'jigsaw_puzzle', 'hog', 'church', 'jigsaw_puzzle', 'lakeside', 'military_uniform', 'clog', 'vestment', 'book_jacket', 'picket_fence', 'jigsaw_puzzle', 'book_jacket', 'rapeseed', 'book_jacket', 'fountain', 'jigsaw_puzzle', 'jigsaw_puzzle', 'church', 'castle', 'jigsaw_puzzle', 'coral_reef', 'barn', 'church', 'mortarboard', 'book_jacket', 'castle', 'coral_reef', 'castle', 'coral_fungus', 'jigsaw_puzzle', 'military_uniform', 'shower_cap', 'forklift', 'comic_book', 'sea_urchin', 'wreck', 'rocking_chair', 'book_jacket', 'throne', 'cliff', 'Airedale', 'drilling_platform', 'ant', 'canoe', 'jigsaw_puzzle', 'coral_reef', 'barn', 'jigsaw_puzzle', 'jigsaw_puzzle', 'cliff', 'honeycomb', 'church', 'coral_reef', 'jigsaw_puzzle', 'diamondback', 'African_hunting_dog', 'lakeside', 'worm_fence', 'book_jacket', 'ice_bear', 'prayer_rug', 'plow', 'trilobite', 'alp', 'jigsaw_puzzle', 'picket_fence', 'jigsaw_puzzle', 'jigsaw_puzzle', 'barn', 'altar', 'jigsaw_puzzle', 'stone_wall', 'book_jacket', 'alp', 'shower_cap', 'book_jacket', 'meerkat', 'prayer_rug', 'cliff', 'jigsaw_puzzle', 'castle', 'stone_wall', 'stole', 'book_jacket', 'rapeseed', 'pot', 'jigsaw_puzzle', 'jigsaw_puzzle', 'frilled_lizard', 'plow', 'comic_book', 'jigsaw_puzzle', 'barn', 'prison', 'castle', 'stone_wall', 'trilobite', 'jigsaw_puzzle', 'jigsaw_puzzle', 'jigsaw_puzzle', 'fountain', 'ant', 'rapeseed', 'cowboy_hat', 'jigsaw_puzzle', 'cheetah', 'parking_meter', 'book_jacket', 'hay', 'wreck', 'book_jacket', 'book_jacket', 'church', 'scuba_diver', 'fountain', 'wreck', 'coral_reef', 'sombrero', 'coral_fungus', 'book_jacket', 'airship', 'book_jacket', 'fountain', 'fountain', 'church', 'fountain', 'barn', 'monastery', 'stone_wall', 'book_jacket', 'wreck', 'window_screen', 'book_jacket', 'stone_wall', 'swing', 'book_jacket', 'jigsaw_puzzle', 'pitcher', 'wreck', 'book_jacket', 'shower_curtain', 'pillow', 'megalith', 'shopping_cart', 'rock_crab', 'envelope', 'book_jacket', 'zebra', 'comic_book', 'book_jacket', 'jigsaw_puzzle', 'jigsaw_puzzle', 'book_jacket', 'valley', 'stone_wall', 'mask', 'alp', 'paintbrush', 'military_uniform', 'totem_pole', 'hen-of-the-woods', 'stone_wall', 'worm_fence', 'lawn_mower', 'rifle', \"potter's_wheel\", 'comic_book', 'hippopotamus', 'shower_curtain', 'book_jacket', 'plow', 'thatch', 'cliff', 'barn', 'jigsaw_puzzle', 'isopod', 'barn', 'book_jacket', 'book_jacket', 'fountain', 'saltshaker', 'dock', 'book_jacket', 'stone_wall', 'baboon', 'barn', 'megalith', 'altar', 'church', 'pot', 'bolo_tie', 'military_uniform', 'thatch', 'padlock', 'hoopskirt', 'envelope', 'envelope', 'book_jacket', 'rapeseed', 'barn', 'candle', 'airship', 'wreck', 'envelope', 'stone_wall', 'tricycle', 'greenhouse', 'jigsaw_puzzle', 'stone_wall', 'jigsaw_puzzle', 'pot', 'jigsaw_puzzle', 'pitcher', 'book_jacket', 'jigsaw_puzzle', 'fountain', 'prayer_rug', 'cliff', 'castle', 'hay', 'head_cabbage', 'jigsaw_puzzle', 'thatch', 'padlock', 'stone_wall', 'church', 'binoculars', 'castle', 'crutch']\n"]}],"source":["# CREATES LIST OF TOP LABEL CLASSES AND CLASS DESCRIPTIONS \n","\n","# print(label_list[0][0][0])  # class\n","# print(label_list[0][0][1])  # class description\n","\n","\n","# list_of_classes = []\n","# list_of_class_desc = []\n","# for item in label_list:\n","#   # Only takes the top label\n","#   list_of_classes.append(item[0][0])\n","#   list_of_class_desc.append(item[0][1])\n","\n","# print(list_of_classes)\n","# print(list_of_class_desc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJAQm16Dlls5"},"outputs":[],"source":["# DATA CLEANING STUFF (SOMEWHAT)\n","# NOTHING GETS ADDED TO THE DIRECTORIES HERE\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# from PIL import Image   NO PILLOW, DOESNT WORK\n","\n","import cv2\n","import os\n","\n","# goal_size = 224, 224\n","directory = os.fsencode('./ADS_Project/Vincent_van_Gogh')\n","    \n","# Only pulls files with even side lengths\n","evenSized_files_list = []\n","for file in os.listdir(directory):\n","\n","  filepath = \"./ADS_Project/Vincent_van_Gogh/\" + str(file)[2:-1]\n","\n","\n","  # Open the image to work with\n","  # cv2.IMREAD_COLOR: It specifies to load a color image.\n","  # cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode\n","  img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n","\n","  width = len(img)\n","  height = len(img[0])\n","\n","  if ((width % 2 == 0) and (height % 2 == 0)):\n","    evenSized_files_list.append(str(file)[2:-1])\n","\n","\n","# Converts each image to a square by cropping\n","# (This approach gets rid of data sadly)\n","good_img_list = []\n","for file in evenSized_files_list:\n","  filepath = \"./ADS_Project/Vincent_van_Gogh/\" + str(file)\n","\n","\n","  # cv2.IMREAD_COLOR: It specifies to load a color image.\n","  # cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode\n","  img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n","\n","  width = len(img)\n","  height = len(img[0])\n","\n","  # Long rectangle\n","  if (width > height):\n","    toCrop = width - height\n","    left = int(toCrop/2)\n","    right = width - left\n","    new_img = img[left:right, 0:height]\n","\n","\n","  # Tall rectangle\n","  else: \n","    toCrop = height - width\n","    top = int(toCrop/2)\n","    bottom = height - top\n","    new_img = img[0:width, top:bottom] \n","\n","  good_img_list.append(new_img)\n","        \n","\n","# Resizes all the images in list to 128 x 128\n","dim = (128, 128)\n","resized_img_list = []\n","for img in good_img_list:\n","\n","  # cv2.INTER_AREA: This is used when we need to shrink an image.\n","  # cv2.INTER_CUBIC: This is slow but more efficient.\n","  # cv2.INTER_LINEAR: This is primarily used when zooming is required. This is the default interpolation technique in OpenCV.\n","\n","  rez_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","  resized_img_list.append(rez_img)\n","  \n","\n","# for img in resized_img_list:\n","#   print(img.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NPprdWBnIMe3"},"outputs":[],"source":["# USED TO CREATE ANOTHER DIRECTORY OF GOOD IMAGES\n","# MAKE SURE VALID/TRAIN/TEST DIRECTORIES ARE EMPTY BEFORE RUNNING\n","\n","from numpy.random.mtrand import random_integers\n","\n","# count = 0\n","# for img in resized_img_list:\n","#   img.save('./resized_Images/resizedFile_' + str(count) + '.jpg', 'JPEG')\n","#   count += 1\n","\n","# MAY CAUSE PROBLEMS\n","random.shuffle(resized_img_list)\n","\n","num_samples = len(resized_img_list)\n","train_ratio = 0.8\n","test_ratio = 0.2\n","val_ratio = 0.2\n","\n","num_train = int(num_samples * train_ratio)\n","num_test = int(num_samples * test_ratio)\n","num_val = int(num_train * val_ratio)\n","\n","count = 1\n","for i in range(1, num_val + 1):\n","  # resized_img_list[i-1].save('./resized_Images/valid/valid_File_' + str(count) + '.jpg', 'JPEG')\n","  cv2.imwrite('./resized_Images/valid/valid_File_' + str(count) + '.jpg', resized_img_list[i-1])\n","  count += 1\n","\n","# Add train images to train directory\n","count = 1\n","for i in range(1, num_train + 1):\n","  # resized_img_list[i-1+num_val].save('./resized_Images/train/train_File_' + str(count) + '.jpg', 'JPEG')\n","  cv2.imwrite('./resized_Images/train/train_File_' + str(count) + '.jpg', resized_img_list[i-1+num_val])\n","  count += 1\n","\n","# Add test images to test directory\n","count = 1\n","for i in range(1, num_test + 1):\n","  # resized_img_list[i-1+num_test].save('./resized_Images/test/test_File_' + str(count) + '.jpg', 'JPEG')\n","  cv2.imwrite('./resized_Images/test/test_File_' + str(count) + '.jpg', resized_img_list[i-1+num_test])\n","  count += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AV3sTcyTZok-"},"outputs":[],"source":["# USED TO DELETE ALL GOOD IMAGES IN DIRECTORIES\n","\n","filepath = './resized_Images/valid/'\n","for f in os.listdir(filepath):\n","    os.remove(filepath + str(f))\n","\n","filepath = './resized_Images/train/'\n","for f in os.listdir(filepath):\n","    os.remove(filepath + str(f))\n","\n","filepath = './resized_Images/test/'\n","for f in os.listdir(filepath):\n","    os.remove(filepath + str(f))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4nQwm29T26Q"},"outputs":[],"source":["# CONVERTS ALL IMAGES FROM DIRECTORIES INTO DATASETS\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# train_path=\"./ADS_Project/Vincent_van_Gogh/\"\n","path=\"./resized_Images\"\n","\n","# keras.applications.imagenet_utils.preprocess_input\n","# keras.applications.resnet50.preprocess_input\n","# keras.applications.vgg16.preprocess_input\n","\n","data_generator = ImageDataGenerator(preprocessing_function=keras.applications.resnet50.preprocess_input)\n","\n","\n","valid_batches = data_generator.flow_from_directory(path, \n","                                                   target_size=(128, 128), \n","                                                   classes=['valid'], \n","                                                   batch_size=32,\n","                                                   class_mode=\"categorical\", \n","                                                   color_mode=\"grayscale\")\n","\n","train_batches = data_generator.flow_from_directory(path, \n","                                                   target_size=(128, 128), \n","                                                   classes=['train'], \n","                                                   batch_size=32, \n","                                                   class_mode=\"categorical\",\n","                                                   color_mode=\"grayscale\")\n","\n","test_batches = data_generator.flow_from_directory(path, \n","                                                  target_size=(128, 128), \n","                                                  classes=['test'], \n","                                                  batch_size=1, \n","                                                  class_mode=\"categorical\",\n","                                                  color_mode=\"grayscale\")\n","\n"]},{"cell_type":"code","source":["# train_imgs, labels = next(train_batches)\n","print(type(train_batches))"],"metadata":{"id":"ahQSJLy3ZBEJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683821861786,"user_tz":240,"elapsed":114,"user":{"displayName":"Jalen Mccloud","userId":"17934253152405445319"}},"outputId":"a2510eb5-1c28-4866-f085-ce2cda8516bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'keras.preprocessing.image.DirectoryIterator'>\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SL8TiyT3AOkA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICl-N_OKDTc-"},"outputs":[],"source":["# PREPARES THE LOSS AND OPTIMIZERS\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D\n","\n","# Adam is going to be the optimizer for both\n","from keras.optimizers import Adam\n","# Binary cross entropy is going to be the loss for both \n","from keras.losses import BinaryCrossentropy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kK0T4TlYLFTR"},"outputs":[],"source":["def build_generator(): \n","    model = Sequential()\n","    \n","    # Beginnings of a generated image\n","    model.add(Dense(7*7*128, input_dim=128))\n","    # model.add(Dense(7*7*128, input_shape=(128, 128, 3)))  # Doesn't work\n","    model.add(LeakyReLU(0.2))\n","    model.add(Reshape((7,7,128)))\n","    \n","    # Upsampling block 1 \n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, 5, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","\n","    # Upsampling block 2 \n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, 5, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","\n","    # Convolutional block 1\n","    model.add(Conv2D(128, 4, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","\n","    # Convolutional block 2\n","    model.add(Conv2D(128, 4, padding='same'))\n","    model.add(LeakyReLU(0.2))\n","    \n","    # Conv layer to get to one channel\n","    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHG-7bd5LdH5"},"outputs":[],"source":["# BUILDS AND TEST THE GENERATOR\n","\n","generator = build_generator()\n","generator.summary()\n","\n","# Generate new fashion\n","gen_imgs = generator.predict(np.random.randn(4,128,1))\n","\n","# Setup the subplot formatting \n","fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n","\n","# Loop four times and get images \n","for idx, img in enumerate(gen_imgs): \n","    # Plot the image using a specific subplot \n","    ax[idx].imshow(np.squeeze(img))\n","    # Appending the image label as the plot title \n","    ax[idx].title.set_text(idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QtCFh6ZLkxT"},"outputs":[],"source":["def build_discriminator(): \n","    model = Sequential()\n","\n","    # Convolutional Block 1\n","    model.add(Conv2D(32, 5, input_shape=(28,28,1)))\n","    # model.add(Conv2D(32, 5, input_shape=(32, 128, 1)))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","\n","    # Convolutional Block 2\n","    model.add(Conv2D(64, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","\n","    # Convolutional Block 3\n","    model.add(Conv2D(128, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","\n","    # Convolutional Block 4\n","    model.add(Conv2D(256, 5))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.4))\n","\n","    # Flatten then pass to dense layer\n","    model.add(Flatten())\n","    model.add(Dropout(0.4))\n","    model.add(Dense(1, activation='sigmoid'))\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uK6JYxaeLltY"},"outputs":[],"source":["# BUILDS AND TEST THE DISCRIMINATOR\n","\n","discriminator = build_discriminator()\n","# discriminator.summary()\n","\n","discriminator.predict(gen_imgs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23t1MTuuL-Iz"},"outputs":[],"source":["g_opt = Adam(learning_rate=0.0001) \n","d_opt = Adam(learning_rate=0.00001) \n","g_loss = BinaryCrossentropy()\n","d_loss = BinaryCrossentropy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvmKwF6NMeg9"},"outputs":[],"source":["from keras.models import Model\n","\n","class MyGAN(Model): \n","    def __init__(self, generator, discriminator, *args, **kwargs):\n","        # Pass through args and kwargs to base class \n","        super().__init__(*args, **kwargs)\n","        \n","        # Create attributes for gen and disc\n","        self.generator = generator \n","        self.discriminator = discriminator \n","        \n","    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n","        # Compile with base class\n","        super().compile(*args, **kwargs)\n","        \n","        # Create attributes for losses and optimizers\n","        self.g_opt = g_opt\n","        self.d_opt = d_opt\n","        self.g_loss = g_loss\n","        self.d_loss = d_loss \n","        \n","    def call(self, x):\n","        # Call generator with input noise\n","        return self.generator(x)\n","        \n","    def train_step(self, batch):\n","      \n","        real_images = batch\n","        fake_images = self(tf.random.normal((128, 128, 1)), training=False)\n","\n","        # Train the discriminator\n","        with tf.GradientTape() as tape:\n","\n","            # Pass real & fake images to discriminator\n","            real_logits = self.discriminator(real_images, training=True)\n","            fake_logits = self.discriminator(fake_images, training=True)\n","            # d_loss = discriminator_loss(real_logits, fake_logits)\n","\n","            # create predictions of labels for real & fake images\n","            yhat_realfake = tf.concat([real_logits, fake_logits], axis=0)\n","\n","            # create predictions of labels for real & fake images\n","            y_realfake = tf.concat([tf.zeroes_like(real_logits), tf.ones_like(fake_logits)], axis=0)\n","\n","            # Add noise to the TRUE outputs\n","            noise_real = 0.15 * tf.random.uniform(tf.shape(real_logits))\n","            noise_fake = -0.15 * tf.random.uniform(tf.shape(fake_logits))\n","            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n","\n","            # Calculate discriminator loss\n","            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n","\n","        # Apply Backpropagation\n","        dgrad = tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n","        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n","\n","        # Train the generator\n","        with tf.GradientTape() as tape:\n","\n","            # Pass real & fake images to generator\n","            gen_images = self.generator(tf.random.normal((128, 128, 1)), training=True)\n","            fake_logits = self.discriminator(fake_images, training=False)\n","            # g_loss = generator_loss(fake_logits)\n","\n","            # Create the predicted labels\n","            predicted_labels = self.discriminator(gen_images, training=False)\n","\n","            # Calculate loss\n","            total_g_loss = self.g_loss(tf.zeroes_like(predicted_labels), predicted_labels)\n","\n","        # Apply Backpropagation\n","        ggrad = tape.gradient(total_g_loss, self.generator.trainable_variables)\n","        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n","\n","\n","        return {\"d_loss\": total_d_loss, \"g_loss\": total_g_loss}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gh_IYefBSshK"},"outputs":[],"source":["subInstance = MyGAN(generator, discriminator)\n","\n","subInstance.compile(g_opt, d_opt, g_loss, d_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIR75ILBTBzB"},"outputs":[],"source":["class ModelMonitor(tf.keras.callbacks.Callback):\n","    def _init_(self, num_img=3, latent_dim=128):\n","      self.num_img = num_img\n","      self.latent_dim = latent_dim\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # print(\"Generating images after epoch %d\" % epoch)\n","\n","        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim, 1))\n","        generated_images = self.model.generator(tf.random.normal((128, 128, 1)), training=False)\n","        generated_images *= 255\n","        generated_images.numpy()\n","        # generated_images = (fake_images + 1.0) / 2.0\n","\n","        for i in range(self.num_img):\n","          img = array_to_img(generated_images[i])\n","          img.save(os.path.join('GAN_Images', f'generated_img{epoch}_{i}.png'))\n","\n","        # save_images(fake_images.numpy(), \"generated_image_%d.png\" % epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGl_vb8XGyMm"},"outputs":[],"source":["# PLOTS IMAGES IN A 1 ROW 10 COLUMN FASHION\n","\n","def plotImages(images_arr):\n","  fig, axes = plt.subplots(1, 10, figsize=(20, 20))\n","  axes = axes.flatten()\n","  for img, ax in zip(images_arr, axes):\n","    ax.imshow(img)\n","    ax.axis('off')\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"CSR_Y9a29_yL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683829217031,"user_tz":240,"elapsed":129,"user":{"displayName":"Jalen Mccloud","userId":"17934253152405445319"}},"outputId":"af5f5899-032a-4b5a-856c-d673670f7f0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["448\n","(128, 128)\n","358\n","358\n"]}],"source":["# print(train_imgs.shape)\n","# print(train_batches[0].shape)\n","print(len(resized_img_list))\n","print(resized_img_list[0].shape)\n","\n","# \n","\n","# valid_batches\n","# train_batches\n","# test_batches\n","\n","print(train_batches.n)\n","print(train_batches.samples)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PFVdjSlSuPH"},"outputs":[],"source":["hist = subInstance.fit(, epochs=20, callbacks=[ModelMonitor()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HC8_IhVcqfqQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iebcdQG1tkpt"},"outputs":[],"source":[" # batch = data[0] # Unpack the tuple to get the image data array\n","        # Get the data\n","\n","        # imgs, labels = next(batch)    # Error - Tuple not an iterator\n","        # img2, labels = next(batch[0]) # Error\n","\n","        # print(batch)                  # Tensor(\"IteratorGetNext:0\", shape=(32, 128, 128, 3), dtype=float32)\n","        # print(batch[0])               # Tensor(\"strided_slice:0\", shape=(128, 128, 3), dtype=float32)\n","        # print(type(batch[0].numpy())) # Error\n","\n","        # Causes shit ton of errors\n","        # print(type(batch[0].eval(session=tf.compat.v1.Session()))) \n","\n","        # print(type(batch))            # Tuple\n","        # print(type(batch[0]))         # tensorflow.python.framework.ops.Tensor\n","        # print(type(imgs))             # Not possible cuz Error\n","        # print(type(img2))             # Not possible cuz Error\n","\n","        # print(type(train_batches))    # keras.preprocessing.image.DirectoryIterator\n","        # print(type(train_batches[0])) # Tuple\n","\n","\n","        # gray_image = np.dot(batch[0][...,:3], [0.2989, 0.5870, 0.1140])\n","        # # # gray image is now (128,128) so we gotta turn it to (128,128,1)\n","        # gray_image = np.expand_dims(gray_image, axis=-1)\n","        # print(gray_image.shape)\n","\n","\n","        # imgs, labels = next(batch)"]},{"cell_type":"code","source":["# # DONT RUN THIS EITHER, NOT NEEDED\n","# # LABELS THE IMAGE DATA\n","\n","# IMAGE_SIZE = 128\n","# BATCH = 32\n","\n","# finished_data = []\n","# model = ResNet50(weights='imagenet')\n","\n","# for img in resized_img_list:\n","\n","#     x = image.img_to_array(img)\n","#     x = np.expand_dims(x, axis=0)\n","#     x = preprocess_input(x)\n","#     preds = model.predict(x)\n","#     finished_data.append((x, preds[0:9]))\n","\n","# dataset = tf.data.Dataset.from_generator(lambda: finished_data,\n","#                                          output_types=(tf.float32, tf.float32),\n","#                                          output_shapes=((1, IMAGE_SIZE, IMAGE_SIZE, 3), (1, 1000)))\n","\n","# dataset = dataset.shuffle(buffer_size=len(finished_data)).batch(batch_size=BATCH)"],"metadata":{"id":"III6TwbE6DN_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMP/BnWz/LgDAiF/ohRdgry"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}